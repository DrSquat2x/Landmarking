
---
title: "How to use the R package 'Landmarking'"
author: Isobel Barrott
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{How to use the R package 'Landmarking'}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r 1,echo=FALSE}
knitr::opts_chunk$set(cache=FALSE,collapse=TRUE, comment="#>")
```

##Performing a landmarking analysis using the R package 'Landmarking'

Below is a step-by-step demonstration about how to use this package. The example used looks at using risk assessments recorded at primary care practices to predict the 5-year risk of cardiovascular disease (CVD).

We will perform the landmarking analysis using both the LOCF and LME longitudinal models and compare the results of these two models. The example involves a competing risks events in the form of the risk of death from other causes; the cause-specific model will as used the survival submodel. For more information about these models please see the separate `What is Landmarking?' PDF file.



### Exploring the datasets

First of all, let's take a look at the datasets we are going to analyse.

There are two datasets:

* `data_repeats` contains repeat measurements data from CVD risk assessments in long format. Each row corresponds to a different assessment and an individual may have multiple assessments. The dataset contains information about an individual's ethnicity, smoking status, diabetes, and standardised systolic blood pressure (SBP). These were recorded on the date specified in `response_date_sbp_stnd`. The standardised total cholesterol to high density lipoprotein (HDL) ratio was also recorded as part of the assessment but was recorded on the date specified in `response_date_tchdl_stnd`, which is up to a month after the other variables were measured.

* `data_outcomes` contains CVD event data, indicating the time and status of event that each individual experiences. There are three types of events: censoring (this is due to loss to follow-up or the end of the study, indicated by status `0`), CVD event (indicated by status `1`), or death from other causes (indicated by status `2`). It is important when using this package that 0 is used to indicate censoring, 1 to indicate the event of interest, and values 2 or above indicate different competing risks.

Both datasets contain column `id` which specifies the patient identifier which is unique to a patient. 

```{r 2}
library(Landmarking)
set.seed(1)
data(data_repeat);head(data_repeat)
data(data_outcomes);head(data_outcomes)
```

Looking further at these datasets we see that there are `r length(unique(data_repeat$id))` patients in this study, each with an average of `r mean(table(data_repeat$id))` assessments.

```{r 3}
length(unique(data_repeat$id)) 
mean(table(data_repeat$id))
```

Moreover, we can see the breakdown of events

```{r 4}
table(data_outcomes$event_status)
```

So `r length(which(data_outcomes$event_status==1))` patients in the study (out of `r dim(data_outcomes)[1]` experienced a CVD event and `r length(which(data_outcomes$event_status==2))` experienced death from other causes.


###Setting Up the Analysis

To use the Landmarking package, the datasets need to be in a certain format. Firstly, instead of the date of the CVD assessment being recorded, the age of the patient should be recorded. These can be calculated as follows.

```{r 5}
data_repeat$response_time_tchdl_stnd<-
    as.numeric((as.Date(data_repeat$response_date_tchdl_stnd,format="yyyy-mm-dd")-as.Date(data_repeat$dob,format="yyyy-mm-dd"))/365.25)
data_repeat$response_time_sbp_stnd<-
    as.numeric((as.Date(data_repeat$response_date_sbp_stnd,format="yyyy-mm-dd")-as.Date(data_repeat$dob,format="yyyy-mm-dd"))/365.25)
```

We also need to define a time of entry into the study and time of exit from the study for each patient. This is necessary in order to work out which individuals are in the risk set at the landmark time. For this study the time of entry into the study is the date of first assessment for an individual. This is the earliest time of `response_time_sbp_stnd` and can be calculated as:

```{r 7}
start_time<-stats::aggregate(stats::as.formula(paste0("response_time_sbp_stnd","~","id")),data_repeat,function(x){min(x)})
names(start_time)[2]<-"start_time"
data_repeat<-dplyr::left_join(data_repeat,start_time,by="id")
```

The patient exits the study either by having an event or being censored at the end of the study on 1st January 2010. All individuals have been censored after this date in the dataset `data_outcome`. The end of study time is therefore simply the `event_time` column. 

Finally, the package Landmarking requires that both datasets are joined into one.

```{r 8}
data_repeat_outcomes<-dplyr::left_join(data_repeat,data_outcomes,by="id")
head(data_repeat_outcomes)
```

We are now ready to begin the analysis using the Landmarking package.

## The Landmarking Analysis

There are a couple of issues to deal with before we start, these stem from the fact that we wish to compare the LOCF and LME longitudinal model. We want to ensure that the same dataset is used for both of these models so that the comparison is fair. 

The first issue is that the presence of `NA` values means that some individuals in the risk set do not have LOCF values for all the covariates. This means that the LOCF longitudinal model cannot be fitted for these individuals, however the LME longitudinal model can allow missing values in the random effects covariates. As we wish that the dataset that both models are fitted are the same, we should consider removing these individuals from the dataset.

Helpfully, the `Landmarking` package contains a function `return_ids_with_LOCF` to create a dataset with individuals with a LOCF for all covariates contained in the `covariates` parameter at landmark time `x_L`.

```{r 9}
data_repeat_outcomes<-return_ids_with_LOCF(data=data_repeat_outcomes,patient_id="id",covariates=c("ethnicity","smoking","diabetes","sbp_stnd","tchdl_stnd"),covariates_time=c(rep("response_time_sbp_stnd",4),"response_time_tchdl_stnd"),x_L=60)
```

The second issue is to do with cross-validation, but we will deal with this once we have fitted the LOCF landmark model.

So we can now  fit the landmark model using the LOCF longitudinal submodel. To demonstrate how to use the package, we use only landmark times 60 and 61 years old however we may wish to use more landmark times in practice. For more information about this function, see the Details section of the `fit_LOCF_landmark_model` documentation.


```{r 11}
data_model_landmark_LOCF<-fit_LOCF_landmark_model(data_long=data_repeat_outcomes,
                                                  x_L=c(60,61),
                                                  x_hor=c(65,66), 
                                                  covariates=c("ethnicity","smoking","diabetes","sbp_stnd","tchdl_stnd"),
                                                  covariates_time=c(rep("response_time_sbp_stnd",4),"response_time_tchdl_stnd"),
                                                  k=10,
                                                  start_study_time="start_time",
                                                  end_study_time="event_time",
                                                  patient_id="id",
                                                  event_time="event_time",
                                                  event_status="event_status",
                                                  survival_submodel = "cause_specific"
                                                  )
```

We can see that fitting this model returns the warnings such as `Loglik converged before variable  2 ; coefficient may be infinite.`. Taking a look at the model fit contained in `data_model_landmark_LOCF$model_survival`, we can see the upper confidence interval for `ethnicityIndian` is `inf` for certain folds. This is due there being few individuals that have ethnicity 'Indian' and few individuals that experienced death from other causes. However, as only the point estimate of the coefficient is needed to calculate the risk prediction, not having the standard error is not a problem. Indeed we have obtained the risk predictions and can take a look at their distribution.


```{r 12}
plot(density(100*data_model_landmark_LOCF[["60"]]$data$event_prediction), xlab="Predicted risk of CVD event (%)",main="Landmark age 60")
```

Printing the object that has been outputted returns a list of datasets corresponding to each of the landmark groups. These contain the column `event_prediction` which indicates the risk prediction of the event of interest.

```{r 13}
data_model_landmark_LOCF
```

The output also contains the prediction error for the model, which is assessed using the Brier score and c-index. The standard error for these estimates can be calculated by setting parameter `b` to the desired number of bootstrap samples. 

```{r 14}
data_model_landmark_LOCF[["60"]]$prediction_error
data_model_landmark_LOCF[["61"]]$prediction_error
```
Now we can move on to fitting the landmark model using the LME longitudinal submodel.  For more information about this function, see the Details section of the `fit_LME_landmark_model` documentation. The variables standardised systolic blood pressure (SBP) and standardised total cholesterol to high density lipoprotein (HDL) ratio are continuous and repeatedly measured and so these are included as random effects in the LME model.  

The second issue which was mentioned previously is related to cross-validation. In particular we wish to perform k-fold cross-validation using exactly the same folds for both LOCF and LME models to ensure a fair comparison. To do this we use the parameter `cross_validation_df` which uses a list of data frames that indicate which fold each individual belongs to. We create this list using the output of `fit_LOCF_landmark_model`.

```{r 15}
cross_validation_list<-lapply(data_model_landmark_LOCF,"[[",i=1)
```

There are a couple of computational considerations to highlight about fitting the LME model. The parameter `lme_control` can be altered in order to change the  default values of parameters (such as maximum number of iterations) for the algorithm which fits the LME model. Also setting `standardise_time = TRUE` standardises time values which helps fitting the LME model (see `help("fit_LME_landmark_model")`).

So we fit the LME landmark model in a similar way to the LOCF landmark model, but with a few extra parameters.

```{r 16}
data_model_landmark_LME<-fit_LME_landmark_model(data_long=data_repeat_outcomes,
                                                  x_L=c(60,61),
                                                  x_hor=c(65,66),
                                                  cross_validation_df=cross_validation_list,
                                                  start_study_time="start_time",
                                                  end_study_time="event_time",
                                                    fixed_effects=c("ethnicity","smoking","diabetes"),
                                                    fixed_effects_time="response_time_sbp_stnd",
                                                    random_effects=c("sbp_stnd","tchdl_stnd"),
                                                    random_effects_time=c("response_time_sbp_stnd","response_time_tchdl_stnd"),
                                                    patient_id="id",
                                                    standardise_time = TRUE,
                                                    lme_control = nlme::lmeControl(maxIter=100,msMaxIter=100),
                                                    event_time="event_time",
                                                    event_status="event_status",
                                                    survival_submodel = "cause_specific")
```

Comparing the prediction error for the landmarking with LOCF and LME, we can see a slight improvement when the LME model is used.

```{r 17}
data_model_landmark_LME[["60"]]$prediction_error
data_model_landmark_LME[["61"]]$prediction_error
```
